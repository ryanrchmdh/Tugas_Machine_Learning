{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10111,"status":"ok","timestamp":1729413097571,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"nSfZ2blDBwR9","outputId":"f8f34266-d67a-44e0-e8ec-4963d776dc4f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Collecting nltk\n","  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: click in c:\\users\\ryan rachmadha f\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in c:\\users\\ryan rachmadha f\\appdata\\roaming\\python\\python313\\site-packages (from nltk) (1.4.2)\n","Collecting regex>=2021.8.3 (from nltk)\n","  Using cached regex-2024.9.11-cp313-cp313-win_amd64.whl.metadata (41 kB)\n","Collecting tqdm (from nltk)\n","  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n","Requirement already satisfied: colorama in c:\\users\\ryan rachmadha f\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk) (0.4.6)\n","Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n","Using cached regex-2024.9.11-cp313-cp313-win_amd64.whl (273 kB)\n","Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n","Installing collected packages: tqdm, regex, nltk\n","Successfully installed nltk-3.9.1 regex-2024.9.11 tqdm-4.66.5\n"]}],"source":["!pip install nltk"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":10928,"status":"ok","timestamp":1729413108494,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"5dtjGOp0BwSG"},"outputs":[],"source":["import nltk"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":831,"status":"ok","timestamp":1729413109320,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"EPBH7BFkBwSH","outputId":"1acd3f7d-88f2-469d-8280-100be5815ccc"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to C:\\Users\\RYAN RACHMADHA\n","[nltk_data]     F\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('punkt')"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1729413109321,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"LebFH0Y3BwSI"},"outputs":[{"ename":"ImportError","evalue":"C extension: pandas.util not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext' to build the C extensions first.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\__init__.py:39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     40\u001b[0m         is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev,  \u001b[38;5;66;03m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     )\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\compat\\__init__.py:26\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressors\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     28\u001b[0m     pa_version_under10p1,\n\u001b[0;32m     29\u001b[0m     pa_version_under11p0,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     pa_version_under17p0,\n\u001b[0;32m     35\u001b[0m )\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\compat\\numpy\\__init__.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas.util'","\nThe above exception was the direct cause of the following exception:\n","\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcorpus\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stopwords\n","File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\__init__.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _err:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     _module \u001b[38;5;241m=\u001b[39m _err\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     45\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC extension: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not built. If you want to import \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas from the source directory, you may need to run \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython setup.py build_ext\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to build the C extensions first.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m_err\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     51\u001b[0m     get_option,\n\u001b[0;32m     52\u001b[0m     set_option,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m     options,\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# let init-time option registration happen\u001b[39;00m\n","\u001b[1;31mImportError\u001b[0m: C extension: pandas.util not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext' to build the C extensions first."]}],"source":["import pandas as pd\n","import numpy as np\n","from nltk.corpus import stopwords\n","from nltk import ngrams\n","from nltk import word_tokenize\n","import string\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn import svm\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from nltk.stem import PorterStemmer\n","from sklearn import metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1729413156927,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"WQTqLg2ZBwSK"},"outputs":[],"source":["df = pd.read_csv(\"C:/Users/RYAN RACHMADHA F/Desktop/File Ryan/University/Sem 7/Machine Learning/Praktikum 1_1217070079_Ryan Rachmadha/Bahan data/ISEAR.csv\")\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1729413156927,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"3tG3FFwkBwSM"},"outputs":[],"source":["col = [0,1]\n","new_df = df [col ]\n","new_df = new_df [pd. notnull(df [1])]\n","new_df . columns = ['Emotion', 'Text']\n","new_df. head()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1729413156927,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"bh4C3W-vBwSN"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","fig = plt.figure(figsize=(8,6))\n","new_df.groupby( 'Emotion' ) . Text. count().plot. bar(ylim=0)\n","plt. show( )"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1729413156927,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"6t35nPkdBwSO"},"outputs":[],"source":["new_df['Text']\n","new_df['Emotion']"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1729413156928,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"xLEr5EvHBwSP"},"outputs":[],"source":["def getTokenizedList(input_df):\n","    tokenizedList=[]\n","    for i in range(0, len(input_df)):\n","        curText = input_df['Text'].iloc[i]\n","        curText = curText.replace('\\n','')\n","        curTokenized=word_tokenize(curText)\n","        tokenizedList.append(curTokenized)\n","    #print(tokenizedList)\n","\n","    tokenziedListWithoutPunct=[]\n","    punctList=list(string.punctuation)\n","    for i in range(0, len(tokenizedList)):\n","        curList=tokenizedList[i]\n","        newList=[] #list without stopwords\n","        for word in curList:\n","            if (word.lower() not in punctList):\n","                newList.append(word.lower())\n","        tokenziedListWithoutPunct.append(newList)\n","\n","    #print(tokenziedListWithoutPunct)\n","#Stemming\n","    mystemmer=PorterStemmer()\n","    tokenziedStemmed=[]\n","    for i in range(0,len(tokenziedListWithoutPunct)):\n","        curList=tokenziedListWithoutPunct[i]\n","        newList=[]\n","        for word in curList:\n","            newList.append(mystemmer.stem(word))\n","        tokenziedStemmed.append(newList)\n","    return tokenziedStemmed"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1729413156928,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"WtCZph39BwSR"},"outputs":[],"source":["def transformSentence(sent):\n","    s = []\n","    sent=sent.replace('\\n','')\n","    sentTokenized=word_tokenize(sent)\n","    s.append (sentTokenized)\n","    sWithoutPunct = []\n","    punctList = list(string.punctuation)\n","    curSentList = s[0]\n","    newSentList = []\n","    for word in curSentList:\n","        if (word.lower() not in punctList):\n","            newSentList.append(word.lower())\n","    sWithoutPunct.append(newSentList)\n","    mystemmer = PorterStemmer()\n","    tokenziedStemmed = []\n","    for i in range(0,len(sWithoutPunct)):\n","        curList=sWithoutPunct[i]\n","        newList=[]\n","        for word in curList:\n","            newList.append(mystemmer.stem(word))\n","        tokenziedStemmed.append(newList)\n","    return tokenziedStemmed"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1729413156928,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"L--UXAVsBwST"},"outputs":[],"source":["!python -m nltk.downloader punkt"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1729413156928,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"Tc4X4BXvBwSW"},"outputs":[],"source":["nltk.download('all')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1729413156929,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"58UKc0WZBwSX"},"outputs":[],"source":["new_df['Text']=getTokenizedList(new_df)\n","#new_df['Text']"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1729413156929,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"PzaRW2uOBwSZ"},"outputs":[],"source":["X_train, X_test, Y_train, Y_test=train_test_split(new_df['Text'],new_df['Emotion'], test_size=.3,random_state=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1729413156929,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"M2CNG1a1BwSa"},"outputs":[],"source":["#Function to pass the list to the Tfidf vectorizer\n","def returnPhrase(inputList):\n","    return inputList\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1729413156929,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"jObkK8KnBwSb"},"outputs":[],"source":["#Extracting features for Naive Bayes\n","\n","myVectorizer=TfidfVectorizer(analyzer='word',tokenizer=returnPhrase,preprocessor=returnPhrase,token_pattern=None,ngram_range=(1,3))\n","myVectorizer.fit(X_train)\n","transformedTrain=myVectorizer.transform(X_train).toarray()\n","transformedTest=myVectorizer.transform(X_test).toarray()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1729413156931,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"gTAn1UVzBwSb"},"outputs":[],"source":["curAlpha=0.33 #smoothing factor in NB\n","NBClassifier=MultinomialNB(alpha=curAlpha)\n","NBClassifier.fit(transformedTrain,Y_train)\n","myPredTest=NBClassifier.predict(transformedTest)\n","print('Best Acc Naive Bayes')\n","#print (curAlpha)\n","print(np.sum(myPredTest==Y_test)/len(Y_test))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1729413156932,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"CnGyGIv9BwSd"},"outputs":[],"source":["print('Metrics Classification Report : Naive Bayes')\n","print(metrics.classification_report(Y_test, myPredTest))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1729413156932,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"2a5Nnpt6BwSe"},"outputs":[],"source":["myVectorizer=TfidfVectorizer(analyzer='word',tokenizer=returnPhrase,preprocessor=returnPhrase,token_pattern=None,ngram_range=(1,3))\n","myVectorizer.fit(X_train)\n","transformedTrain=myVectorizer.transform(X_train).toarray()\n","transformedTest=myVectorizer.transform(X_test).toarray()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1729413156932,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"Kxr73-rrBwSe"},"outputs":[],"source":["curC=2    #cost factor in SVM\n","SVMClassifier=svm.LinearSVC(C=curC)\n","SVMClassifier.fit(transformedTrain,Y_train)\n","myPredTest=SVMClassifier.predict(transformedTest)\n","print('Best Acc SVM')\n","#print (curC)\n","print(np.sum(myPredTest==Y_test)/len(Y_test))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1729413156932,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"9ZQSJuM1BwSf"},"outputs":[],"source":["print('Metrics Classification Report : SVM')\n","print(metrics. classification_report(Y_test, myPredTest))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1729413156932,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"Gpmi4IFlBwSg"},"outputs":[],"source":["#To predict the emotion of a sentence using Naive Bayes\n","def predictSentNB(sent):\n","    sentPred = NBClassifier.predict(myVectorizer. transform(transformSentence(sent)).toarray())\n","    return sentPred\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1729413156932,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"JnKwzBbSBwSg"},"outputs":[],"source":["#To predict the emotion of a sentence using Naive Bayes\n","def predictSentSVM(sent):\n","    sentPred = SVMClassifier.predict(myVectorizer. transform(transformSentence(sent)).toarray())\n","    return sentPred\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1729413156932,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"lH14xTAdBwSh"},"outputs":[],"source":["sent = \"I love you to the moon and back\"\n","\n","#Printing the predicted emotion\n","print(\"Navie bayes prediction\")\n","print(predictSentNB(sent))\n","print(\"SVM prediction\")\n","print(predictSentSVM(sent))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1729413156932,"user":{"displayName":"Ryan Rachmadha","userId":"04919096183808385082"},"user_tz":-420},"id":"5ZAZNc8HBwSi"},"outputs":[],"source":["#printing the Confusion Matrix\n","\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt # Import matplotlib for plotting\n","\n","labels = ['anger','disgust','fear','guilt','joy','sadness','shame']\n","cm = confusion_matrix(Y_test, myPredTest, labels=labels) # Pass labels as a keyword argument\n","#print(cm)\n","fig, ax = plt.subplots(figsize=(7,7))\n","sns.heatmap(cm, annot=True,fmt='d',\n","            xticklabels=labels, yticklabels=labels,cmap='Blues')\n","plt.ylabel('Actual Emotions')\n","plt.xlabel('Predicted Emotions')\n","plt.show()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.0"}},"nbformat":4,"nbformat_minor":0}
